# AWS CUR Report Generator - Project Context

## Project Overview

This is an AWS Cost and Usage Report (CUR) generator that reads CUR data from S3 and generates comprehensive visual reports. The tool is designed to be easily shareable and provides deeper insights than standard AWS billing reports.

**Key Requirements:**
- Easy to use and shareable
- Visual reports from S3 CUR data
- Environment variables for configuration (NO SECRETS IN CODE)
- In-depth cost analysis by account and service
- Much deeper analysis than standard billing reports

## Technology Stack

- **Language:** Python 3.9+
- **Package Manager:** uv (modern, fast alternative to pip)
- **Key Libraries:**
  - boto3: AWS S3 access
  - pandas: Data processing
  - plotly: Interactive visualizations
  - click: CLI interface
  - python-dotenv: Environment variable management
- **Development:**
  - pytest: Testing framework (72 tests, 96% coverage)
  - ruff: Linting
  - mypy/pyright: Type checking
  - black: Code formatting

## Project Structure

```
aws-cur-report-generator/
├── src/
│   ├── s3_reader.py       # Reads CUR files from S3 (CSV, CSV.GZ, Parquet)
│   ├── data_processor.py  # Processes and analyzes CUR data
│   └── visualizer.py      # Creates Plotly visualizations and HTML reports
├── tests/
│   ├── conftest.py        # Pytest fixtures (6 months of mock data)
│   ├── test_s3_reader.py  # S3 reader tests (25 tests)
│   ├── test_data_processor.py  # Data processor tests (19 tests)
│   ├── test_visualizer.py      # Visualizer tests (17 tests)
│   ├── test_cli.py        # CLI tests (14 tests)
│   └── test_examples.py   # Example report generation (3 tests)
├── examples/
│   ├── example_report.html  # Example interactive HTML report
│   └── *.csv               # Example CSV exports
├── cur_report_generator.py  # Main CLI entry point
├── pyproject.toml          # Project configuration and dependencies
├── .env.example           # Example environment configuration
└── README.md              # User documentation

## Architecture

### 1. S3 Reader (`src/s3_reader.py`)
**Purpose:** Handles reading CUR files from S3

**Key Features:**
- Supports CSV, gzipped CSV, and Parquet formats
- Handles AWS credentials via boto3 sessions
- Date-based filtering of CUR files
- Sample file mode for testing

**Important Methods:**
- `list_report_files()`: Lists CUR files in S3 bucket
- `read_cur_file()`: Reads a single CUR file
- `load_cur_data()`: Main method to load CUR data with date filtering

**Type Note:** Line 116 has `# type: ignore[arg-type]` for GzipFile - this is a known pandas typing issue where GzipFile works at runtime but type stubs don't recognize it.

### 2. Data Processor (`src/data_processor.py`)
**Purpose:** Processes and analyzes CUR data

**Key Features:**
- Normalizes column names across different CUR versions
- Handles multiple CUR column naming conventions
- Calculates cost aggregations (by service, account, region)
- Detects cost anomalies using z-scores
- Computes moving averages (7-day, 30-day)

**Important Methods:**
- `prepare_data()`: Cleans and normalizes CUR data
- `get_cost_by_service()`: Service cost aggregation
- `get_cost_by_account()`: Account cost aggregation
- `get_cost_by_account_and_service()`: Multi-dimensional breakdown
- `get_daily_cost_trend()`: Daily trends with moving averages
- `detect_cost_anomalies()`: Statistical outlier detection
- `get_summary_statistics()`: Overall cost statistics

**Type Safety:** Uses explicit `pd.Series` and `pd.DataFrame` type annotations to avoid ndarray inference issues with pyright. Uses `# type: ignore[assignment]` where needed for DataFrame column access.

### 3. Visualizer (`src/visualizer.py`)
**Purpose:** Creates interactive Plotly visualizations

**Key Features:**
- 11 different chart types
- Self-contained HTML reports (no external dependencies)
- Plotly White theme for clean appearance
- Fixed heatmap to use plain JavaScript arrays (not binary encoding)

**Chart Types:**
1. Cost by Service (bar chart)
2. Cost by Account (bar chart)
3. Daily Cost Trends with Moving Averages (line chart)
4. Service Cost Trends (multi-line chart)
5. Account Cost Trends (multi-line chart)
6. Account vs Service Heatmap
7. Service Cost Distribution (pie chart)
8. Account Cost Distribution (pie chart)
9. Monthly Summary (bar chart)
10. Cost Anomalies (scatter plot)
11. Cost by Region (bar chart)

**Important Method:**
- `generate_html_report()`: Creates self-contained HTML file with all charts

**Type Note:** Line 345 converts Index to string for dictionary key to avoid unhashable type error.

### 4. CLI (`cur_report_generator.py`)
**Purpose:** Main command-line interface

**Key Features:**
- Click-based CLI with colorized output
- Environment variable configuration
- Progress indicators
- Date range handling
- Output format options (HTML, CSV)

**Type Note:** Lines 113-114 have assertions after `validate_env_vars()` to tell the type checker that bucket/prefix are not None.

## Data Model

### Mock Data (6 Months, Jan-Jun 2024)

The test fixtures generate realistic 6-month CUR data with dramatically distinct patterns:

**Production Account (123456789012) - $5.4M (87% of total):**
- **EC2:** $8-13K/day, steadily growing (cloud migration pattern)
- **RDS:** $6.5-7.5K/day, very stable (production databases)
- **S3:** $2.8-4.2K/day, continuous growth (data lake accumulation)
- **CloudFront:** $2-4.5K/day, weekday peaks (production website traffic)
- **DynamoDB:** $2.2-3.7K/day, scaling up monthly
- **Lambda:** $1K/day, consistent serverless usage

**Development Account (210987654321) - $771K (13% of total):**
- **EC2:** $240-560/day baseline → **HUGE 5-8x spikes every 14 days** (load testing)
- **RDS:** $600-1.2K/day → **spikes to 3-4K every 10 days** (database testing)
- **Lambda:** $15-45/day → **MASSIVE 8-15x spikes** (integration testing)
- **CloudFront:** $80-600/day, testing only, **OFF on weekends**
- **DynamoDB:** $480-720/day, **DECLINING** (migrating to RDS)
- **S3:** $350-530/day, stable storage

**Total Example Cost:** $6.2M over 6 months (182 days)

## Configuration

Required environment variables (set in `.env`):
```bash
CUR_BUCKET=my-cur-bucket      # S3 bucket containing CUR reports
CUR_PREFIX=cur-reports/       # S3 prefix/path to CUR files
AWS_PROFILE=default           # (Optional) AWS profile to use
AWS_REGION=us-east-1          # AWS region
OUTPUT_DIR=reports            # Output directory for generated reports
```

## Common Commands

```bash
# Install dependencies
uv sync

# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src --cov-report=html

# Type checking
uv run mypy src/ cur_report_generator.py --ignore-missing-imports
uv run pyright src/ cur_report_generator.py  # More strict

# Linting
uv run ruff check .
uv run ruff check --fix .

# Generate example report
uv run pytest tests/test_examples.py::TestExampleReports::test_generate_example_html_report

# Run the tool
uv run python cur_report_generator.py --help
uv run python cur_report_generator.py --start-date 2024-01-01 --end-date 2024-06-30
```

## Development History

### Initial Setup
- Created Python-based CLI tool with three core modules
- Interactive Plotly visualizations
- HTML and CSV output options

### Key Improvements
1. **Switched to uv package manager** (user requested modern tooling)
2. **Added comprehensive test suite** (72 tests with 96% coverage)
3. **Fixed Python version** (3.8 → 3.9 due to pandas 2.1.0+ requirement)
4. **Generated example reports** with mock data
5. **Improved mock data quality**:
   - Changed from 31 days to 6 months (182 days)
   - Increased from $655K to $6.2M total for better visibility
   - Created dramatically distinct patterns for each account and service
6. **Fixed heatmap rendering** (converted numpy arrays to plain lists for browser compatibility)
7. **Resolved all linting issues** (35 ruff errors fixed)
8. **Resolved all type checking issues** (17 pyright errors fixed)

### Type Checking Challenges Solved

**pandas Type Inference Issues:**
- DataFrame column access (`df['col']`) can return Series, DataFrame, or ndarray depending on context
- Solution: Explicit type annotations with `# type: ignore[assignment]` where needed
- Pattern: `col: pd.Series = df['column']  # type: ignore[assignment]`

**GzipFile with pandas.read_csv:**
- pandas type stubs don't recognize GzipFile as valid input
- Solution: `# type: ignore[arg-type]` comment
- Works perfectly at runtime, just a stub limitation

**sort_values() typing:**
- Pyright requires explicit `by=` parameter for proper typing
- Changed `df.sort_values('col')` → `df.sort_values(by='col')`

**Environment variable validation:**
- `os.getenv()` returns `str | None`
- Solution: Assert non-None after validation function
- Pattern: `assert var is not None` after validation

## Important Code Patterns

### Pandas Column Access for Type Safety
```python
# Avoid ndarray inference
account_col: pd.Series = df['account_id']  # type: ignore[assignment]
filtered: pd.DataFrame = df[account_col.isin(values)]  # type: ignore[assignment]
```

### DataFrame Filtering and Grouping
```python
# Safe pattern for filtering and aggregating
result = filtered_df.groupby(['col1', 'col2']).agg({'cost': 'sum'}).reset_index()
result = result.sort_values(by='col')  # Use by= for type safety
```

### Heatmap Data Preparation
```python
# Convert to lists for browser compatibility (not binary encoding)
pivot_df = df.pivot(index='account_id', columns='service', values='total_cost')
pivot_df = pivot_df.fillna(0)

fig = go.Figure(data=go.Heatmap(
    z=pivot_df.values.tolist(),  # Convert to list, not numpy array
    x=pivot_df.columns.tolist(),
    y=pivot_df.index.tolist(),
    ...
))
```

## Testing Strategy

- **Unit tests:** Each module tested independently
- **Integration tests:** End-to-end example generation
- **Mock data:** Realistic 6-month patterns for demonstration
- **Coverage:** 96% overall, 100% on visualizer
- **Test isolation:** Each test uses fixtures, no shared state

## Known Issues & Limitations

1. **Import resolution in tests:** Tests use `sys.path.insert()` which pyright can't resolve (expected, doesn't affect functionality)
2. **Type stubs:** Some pandas/plotly type stubs are incomplete (handled with targeted `# type: ignore` comments)
3. **CUR format variations:** Handles most common formats but may need updates for new AWS CUR versions

## Future Agent Notes

### When modifying code:
1. **Always run type checking:** `uv run pyright src/ cur_report_generator.py`
2. **Use explicit pandas types:** Avoid letting pyright infer ndarray
3. **Maintain test coverage:** Add tests for new features
4. **Update mock data carefully:** Changes affect all example outputs
5. **Check example report:** Regenerate after data changes

### When adding new visualizations:
1. Add method to `visualizer.py`
2. Add test to `test_visualizer.py`
3. Add to `test_examples.py` example report
4. Document in this file

### When debugging type errors:
1. Check with `PYTHONPATH=./src pyright file.py`
2. Look for DataFrame column access without type hints
3. Use explicit `pd.Series` / `pd.DataFrame` annotations
4. Add `# type: ignore[assignment]` only when necessary and comment why

## Chart Display Verification

All charts are verified to contain correct data:
- Account trend chart: 2 lines with 182 data points each
- Heatmap: 2 accounts × 6 services (or top N based on parameters)
- All data encoded as plain JavaScript arrays (not binary)

If charts appear empty in browser:
1. Check browser console for JavaScript errors
2. Hard refresh (Ctrl+Shift+R)
3. Verify Plotly.js is loading
4. Check if data is in HTML source (grep for chart name)

## Contact & Resources

- **AWS CUR Documentation:** https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html
- **Plotly Documentation:** https://plotly.com/python/
- **uv Documentation:** https://github.com/astral-sh/uv
